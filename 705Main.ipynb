{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "705Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXvBWYFvDWaqeXhw5eJfTG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamieCDev20/GAM705/blob/main/705Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "0sile4crkxtB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "CgROgKUq4KBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyquaternion\n",
        "!pip install PyDrive"
      ],
      "metadata": {
        "id": "xMlNt9EYOaXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pyquaternion import Quaternion\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from random import random as r"
      ],
      "metadata": {
        "id": "8EzXJwOi4Jqu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "3MkbBYWxOq0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "File Reader"
      ],
      "metadata": {
        "id": "89gQzpdQkJ8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pKPS4kSfUh9"
      },
      "outputs": [],
      "source": [
        "class AnimFileReader():\n",
        "  ## \"#\" breaks between nodes | \":\" breaks between values\n",
        "\n",
        "  def __init__(self, _path):\n",
        "    self.path = _path\n",
        "    self.animData = np.array(float)\n",
        "    self.__ReadAnim__(self.path)\n",
        "\n",
        "  def __ReadAnim__(self, path):\n",
        "    file = open(path, 'r')\n",
        "    overallData = file.read()\n",
        "    overallData = overallData.split(\"SS\")\n",
        "    \n",
        "    del overallData[0]\n",
        "\n",
        "    jointCount = len(overallData)\n",
        "    frameCount = len(overallData[0].split('#')[0].split(':')) - 1\n",
        "    \n",
        "    dataLayer = np.array(float)\n",
        "\n",
        "    trainingData = np.array(float)\n",
        "\n",
        "    for j in range(0, frameCount):\n",
        "      for i in range(0, jointCount):\n",
        "\n",
        "        rots = overallData[i].split('#')[0].split(':')\n",
        "        poss = overallData[i].split('#')[1].split(':')\n",
        "\n",
        "        del rots[0]\n",
        "        del poss[0]\n",
        "\n",
        "        #print(len(rots))\n",
        "        #print(rots[0], rots[1], rots[2], rots[3])\n",
        "        #print(dataLayer.shape)\n",
        "        temp = rots[j].split(',')\n",
        "        dataLayer = np.append(dataLayer, temp)\n",
        "        \n",
        "        temp = poss[j].split(',')\n",
        "        dataLayer = np.append(dataLayer, temp)\n",
        "        #print(dataLayer.shape)\n",
        "      dataLayer = np.delete(dataLayer, 0)\n",
        "      trainingData = np.append(trainingData, dataLayer);\n",
        "      dataLayer = np.array(float)\n",
        "      print(\"Completed: \", j + 1)\n",
        "\n",
        "    print(\"Total its: \", (i + 1) * (j + 1))\n",
        "    \n",
        "    trainingData = np.delete(trainingData, 0)\n",
        "    \n",
        "    print(trainingData.shape)\n",
        "    print(trainingData[0])\n",
        "    \n",
        "    self.animData = trainingData;\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#File Read"
      ],
      "metadata": {
        "id": "41qrnpkqOmSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fr = AnimFileReader(\"SHO_EXORCISMWALK_1_UNCLEAN.txt\")"
      ],
      "metadata": {
        "id": "TCeJzuqAoLB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = fr.animData\n",
        "print(fr.animData.shape)\n",
        "print(data.shape)\n",
        "data = np.reshape(data, [221, 168])\n",
        "print(fr.animData.shape)\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "cMdludDDT3Yr",
        "outputId": "aa925bc0-abf9-4909-e94c-ae24ecefcad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37128,)\n",
            "(37128,)\n",
            "(37128,)\n",
            "(221, 168)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network = Sequential(\n",
        "    Input()\n",
        ")"
      ],
      "metadata": {
        "id": "lGbrt3MgNHds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "cIHrV1o35KSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1, 2, 3, 4, 5], float)\n",
        "b = np.array([6, 6, 6, 6, 6], float)\n",
        "c = b-a\n",
        "b = np.append(b, c);\n",
        "\n",
        "print(b)\n"
      ],
      "metadata": {
        "id": "fhZI5Kub5J9c",
        "outputId": "3a2c6bec-4310-4ea3-d24e-133ece7b7024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6. 6. 6. 6. 6. 5. 4. 3. 2. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GAN Training"
      ],
      "metadata": {
        "id": "HwXCl4LPQK0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Networks"
      ],
      "metadata": {
        "id": "rkK3pOeuR8Gs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator"
      ],
      "metadata": {
        "id": "ZPHdgVl2RhEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Sequential([\n",
        "    Input(shape=(1)),\n",
        "    Dense(5, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "discriminator.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"Accuracy\"])"
      ],
      "metadata": {
        "id": "JEXLQLiSQM2Y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator"
      ],
      "metadata": {
        "id": "tw0Ye_lFRjm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Sequential([\n",
        "      Input(shape=(1)),\n",
        "      Dense(5, activation='relu'),\n",
        "      Dense(1)\n",
        "])\n",
        "generator.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"Accuracy\"])"
      ],
      "metadata": {
        "id": "dNT2ka7dRlE2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Structure"
      ],
      "metadata": {
        "id": "Z_HgrFkvR3sP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Vars"
      ],
      "metadata": {
        "id": "RwdpGyzYTt2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batchSize = 64\n",
        "iterations = 10000\n",
        "fakeDistribution = 0.5"
      ],
      "metadata": {
        "id": "bZC3hJHVR6J5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Func(x):\n",
        "  return [[0.08 * (x[0]-25)**2]]"
      ],
      "metadata": {
        "id": "9JcEOpefV5gR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GenerateBatch():\n",
        "  batchDistribution = np.random.rand(batchSize)\n",
        "  batchDistribution = [(0, 1)[int(x > fakeDistribution)] for x in batchDistribution]\n",
        "  xTrain = [[generator.predict, Func][x] for x in batchDistribution]\n",
        "  return xTrain, batchDistribution\n",
        "\n",
        "##a = [generator.predict, Func][0]\n",
        "##print(a([12]))"
      ],
      "metadata": {
        "id": "iwwmKLtmV-SD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "tKvU6iKUX-ZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(iterations):\n",
        "  print(\"Iteration: \", i)\n",
        "  discrimBatch = []\n",
        "  genBatch = []\n",
        "  randomNums = []\n",
        "  genTrue = []\n",
        "  xTrainSetup, distribution = GenerateBatch()\n",
        "  \n",
        "  for j in range(batchSize):\n",
        "    a = r()*50\n",
        "    randomNums.append(a)\n",
        "    discrimBatch.append(xTrainSetup[j]([a]))\n",
        "  \n",
        "  discriminator.fit(np.array(discrimBatch), np.array(distribution), batchSize, verbose=0)\n",
        "  results = discriminator.predict(np.array(discrimBatch))\n",
        "\n",
        "  for j in range(batchSize):\n",
        "    if distribution[j] == 0:\n",
        "      genTrue.append(1-results[j])\n",
        "      genBatch.append(randomNums[j])\n",
        "    \n",
        "  generator.fit(np.array(genBatch), np.array(genTrue), verbose=0)"
      ],
      "metadata": {
        "id": "bBo7oe3gYBuX",
        "outputId": "df236865-1eac-47e7-815f-a9da6c623def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "Iteration:  1\n",
            "Iteration:  2\n",
            "Iteration:  3\n",
            "Iteration:  4\n",
            "Iteration:  5\n",
            "Iteration:  6\n",
            "Iteration:  7\n",
            "Iteration:  8\n",
            "Iteration:  9\n",
            "Iteration:  10\n",
            "Iteration:  11\n",
            "Iteration:  12\n",
            "Iteration:  13\n",
            "Iteration:  14\n",
            "Iteration:  15\n",
            "Iteration:  16\n",
            "Iteration:  17\n",
            "Iteration:  18\n",
            "Iteration:  19\n",
            "Iteration:  20\n",
            "Iteration:  21\n",
            "Iteration:  22\n",
            "Iteration:  23\n",
            "Iteration:  24\n",
            "Iteration:  25\n",
            "Iteration:  26\n",
            "Iteration:  27\n",
            "Iteration:  28\n",
            "Iteration:  29\n",
            "Iteration:  30\n",
            "Iteration:  31\n",
            "Iteration:  32\n",
            "Iteration:  33\n",
            "Iteration:  34\n",
            "Iteration:  35\n",
            "Iteration:  36\n",
            "Iteration:  37\n",
            "Iteration:  38\n",
            "Iteration:  39\n",
            "Iteration:  40\n",
            "Iteration:  41\n",
            "Iteration:  42\n",
            "Iteration:  43\n",
            "Iteration:  44\n",
            "Iteration:  45\n",
            "Iteration:  46\n",
            "Iteration:  47\n",
            "Iteration:  48\n",
            "Iteration:  49\n",
            "Iteration:  50\n",
            "Iteration:  51\n",
            "Iteration:  52\n",
            "Iteration:  53\n",
            "Iteration:  54\n",
            "Iteration:  55\n",
            "Iteration:  56\n",
            "Iteration:  57\n",
            "Iteration:  58\n",
            "Iteration:  59\n",
            "Iteration:  60\n",
            "Iteration:  61\n",
            "Iteration:  62\n",
            "Iteration:  63\n",
            "Iteration:  64\n",
            "Iteration:  65\n",
            "Iteration:  66\n",
            "Iteration:  67\n",
            "Iteration:  68\n",
            "Iteration:  69\n",
            "Iteration:  70\n",
            "Iteration:  71\n",
            "Iteration:  72\n",
            "Iteration:  73\n",
            "Iteration:  74\n",
            "Iteration:  75\n",
            "Iteration:  76\n",
            "Iteration:  77\n",
            "Iteration:  78\n",
            "Iteration:  79\n",
            "Iteration:  80\n",
            "Iteration:  81\n",
            "Iteration:  82\n",
            "Iteration:  83\n",
            "Iteration:  84\n",
            "Iteration:  85\n",
            "Iteration:  86\n",
            "Iteration:  87\n",
            "Iteration:  88\n",
            "Iteration:  89\n",
            "Iteration:  90\n",
            "Iteration:  91\n",
            "Iteration:  92\n",
            "Iteration:  93\n",
            "Iteration:  94\n",
            "Iteration:  95\n",
            "Iteration:  96\n",
            "Iteration:  97\n",
            "Iteration:  98\n",
            "Iteration:  99\n",
            "Iteration:  100\n",
            "Iteration:  101\n",
            "Iteration:  102\n",
            "Iteration:  103\n",
            "Iteration:  104\n",
            "Iteration:  105\n",
            "Iteration:  106\n",
            "Iteration:  107\n",
            "Iteration:  108\n",
            "Iteration:  109\n",
            "Iteration:  110\n",
            "Iteration:  111\n",
            "Iteration:  112\n",
            "Iteration:  113\n",
            "Iteration:  114\n",
            "Iteration:  115\n",
            "Iteration:  116\n",
            "Iteration:  117\n",
            "Iteration:  118\n",
            "Iteration:  119\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a64ec62247b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrandomNums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdiscrimBatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTrainSetup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscrimBatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1976\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1977\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1978\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1979\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 755\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m         \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         self._resource_deleter = IteratorResourceDeleter(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3315\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3316\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3317\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3318\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = np.array([0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 244, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50])\n",
        "print(generator.predict(test))"
      ],
      "metadata": {
        "id": "qt38IUKEBriL",
        "outputId": "20e6cf74-0705-4bea-c746-a0f38bbdec98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.16484973]\n",
            " [0.22262654]\n",
            " [0.28040338]\n",
            " [0.33818018]\n",
            " [0.39595702]\n",
            " [0.45373383]\n",
            " [0.5115107 ]\n",
            " [0.56928754]\n",
            " [0.62706435]\n",
            " [0.68484116]\n",
            " [0.74261796]\n",
            " [0.80039483]\n",
            " [7.2136226 ]\n",
            " [0.91594845]\n",
            " [0.97372526]\n",
            " [1.0315021 ]\n",
            " [1.0892789 ]\n",
            " [1.1470556 ]\n",
            " [1.2048326 ]\n",
            " [1.2626095 ]\n",
            " [1.3203862 ]\n",
            " [1.3781631 ]\n",
            " [1.4359398 ]\n",
            " [1.4937167 ]\n",
            " [1.5514936 ]\n",
            " [1.6092703 ]]\n"
          ]
        }
      ]
    }
  ]
}